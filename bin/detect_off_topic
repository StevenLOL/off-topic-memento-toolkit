#!/usr/bin/env python

import sys
import logging
import argparse

import offtopic

def process_arguments(args):

    parser = argparse.ArgumentParser(prog="python {}".format(args[0]),
        description='Detecting off-topic webpages.',
        formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument('-i', '--input', dest='input_type',
        required=True, type=offtopic.process_input_types,
        help="input data to use with one of the following:\n"
        "* warc=[warc-filenames separated by commas with no spaces] - EXPERIMENTAL\n"
        "* archiveit=[collection identifier or collection URI]\n"
        "* timemap=[URI of TimeMap]\n"
        "* goldtest=[tab-separated gold standard data file]"
        "* dir=[existing input directory from prior run]"
        )

    parser.add_argument('-o', '--output', dest='output_filename', 
        required=True, help="file name in which to store the scores")

    parser.add_argument('-d', '--directory', dest='working_directory',
        default='/tmp/working',
        help='The working directory holding the data being downloaded'
        ' and processed.')

    parser.add_argument('-t', '--output-type', dest='output_type',
        default='json', help="output type for off-topic analysis:\n"
        "* JSON - a JSON file containing the memento offtopic status(default)\n"
        "* goldtest - a TSV file in the same format as the gold standard data"
        )

    measurehelp = ""
    for measure in offtopic.supported_measures:
        measurehelp += "* {} - {}, default threshold {}\n".format(
            measure, offtopic.supported_measures[measure]['name'],
            offtopic.supported_measures[measure]['default_threshold'])

    parser.add_argument('-m', '--measures', dest='measures',
        default="cosine=0.15,wordcount=-0.85",
        type=offtopic.process_similarity_measure_inputs,
        help="similarity measures to use, separated by commas with no spaces\n"
        "with thresholds after (e.g., jaccard=0.10,cosine=0.15,wcount);\n"
        "leave thresholds off to use default thresholds;\n"
        "accepted values:\n{}".format(measurehelp)
        )

    parser.add_argument('-l', '--logfile', dest='logfile',
        default=sys.stdout,
        help="path to logging file")

    parser.add_argument('-v', '--verbose', dest='verbose',
        action='store_true',
        help="raise the logging level to debug for more verbose output")

    return parser.parse_args()

if __name__ == '__main__':

    args = process_arguments(sys.argv)

    # set up logging for the rest of the system
    logger = offtopic.get_logger(
        __name__, offtopic.calculate_loglevel(args.verbose), 
        args.logfile)

    logger.info('Starting topic analysis run.')
    logger.debug('command-line arguments: {}'.format(args))

    input_type = args.input_type[0]
    input_type_arguments = args.input_type[1]

    logger.debug("measures: {}".format(args.measures))

    cm = offtopic.get_collection_model(
        input_type, input_type_arguments, args.working_directory
    )

    scoring = {}

    for measure in args.measures:

        logger.info("Processing mementos using measure {}".format(measure))
        threshold = args.measures[measure]
        scoring[measure] = offtopic.supported_measures[measure]["function"](cm)
        scoring[measure] = offtopic.evaluate_off_topic(
            scoring[measure], 
            offtopic.supported_measures[measure]["default_threshold"])

    with open(args.output_filename, "w") as outputfile:
        offtopic.supported_output_types[args.output_type](outputfile, scoring, cm)

    logger.info("output written to {}".format(args.output_filename))

    logger.info("Finished analysis run")